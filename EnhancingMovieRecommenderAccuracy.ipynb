{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Enhancing Movie Recommender Accuracy - A Comprehensive Study on Hyperparameter Optimization and Genre-Specific Error Analysis in Spark</h1>\n",
    "\n",
    "<h2 align=\"center\">Sai Sanwariya Narayan</h2>\n",
    "\n",
    "\n",
    "### Tasks:\n",
    "    - Use the best hyper-parameters found in ALS-Powered-Movie-Recommender to construct an ALS model.\n",
    "    - Compute average prediction error for each movie and genre.\n",
    "    - Analyze the relationship between the number of reviews a movie has and the prediction error.\n",
    "    - Use `persist()` and `unpersist()` to manage performance.\n",
    "    - Utilize Spark DataFrame and RDD transformations and actions for data processing and analysis.\n",
    "\n",
    "### Key Components:\n",
    "- **Data Preparation**: Reading and preprocessing movie and ratings data into Spark DataFrames and RDDs.\n",
    "- **Model Building**: Constructing an ALS model with the best hyper-parameters.\n",
    "- **Model Evaluation**: Generating predictions, calculating prediction errors, and joining RDDs/DataFrames for analysis.\n",
    "- **Analysis**:\n",
    "    - Calculating average prediction error for each movie.\n",
    "    - Examining the correlation between the number of reviews and prediction error.\n",
    "    - Analyzing the prediction errors by movie genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebook running pyspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once we import pyspark, we need to import \"SparkContext\".  Every spark program needs a SparkContext object. In order to use Spark SQL and Spark DataFrames, we also need to import SparkSession from PySpark.SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, IntegerType, FloatType\n",
    "from pyspark.sql.functions import col, column\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql import Row\n",
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We then create a Spark Session variable in order to use DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=SparkSession.builder.master(\"local\").appName(\"Lab7B ALS Model Weakness Eval\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.sparkContext.setCheckpointDir(\"~/scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_schema = StructType([ StructField(\"UserID\", IntegerType(), False ), \\\n",
    "                            StructField(\"MovieID\", IntegerType(), True), \\\n",
    "                            StructField(\"Rating\", FloatType(), True ), \\\n",
    "                            StructField(\"RatingID\", IntegerType(), True ), \\\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_DF = ss.read.csv(\"/storage/home/ratings_2.csv\", schema=rating_schema, header=True, inferSchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserID: integer (nullable = true)\n",
      " |-- MovieID: integer (nullable = true)\n",
      " |-- Rating: float (nullable = true)\n",
      " |-- RatingID: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_DF = ratings_DF.select(\"UserID\",\"MovieID\",\"Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(UserID=1, MovieID=31, Rating=2.5),\n",
       " Row(UserID=1, MovieID=1029, Rating=3.0),\n",
       " Row(UserID=1, MovieID=1061, Rating=3.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings2_RDD = ratings2_DF.rdd\n",
    "ratings2_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_schema = StructType([ StructField(\"MovieID\", IntegerType(), False), \\\n",
    "                            StructField(\"MovieTitle\", StringType(), True ), \\\n",
    "                            StructField(\"Genres\", StringType(), True ), \\\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_DF = ss.read.csv(\"/storage/home/movies_2.csv\", schema=movie_schema, header=True, inferSchema=False)\n",
    "# In the cluster mode, we need to change to `header=False` because it does not have header."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below transforms the entire ratings dataset into a format for model input, which will be used for generating model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_input_RDD = ratings2_RDD.map(lambda x: (x[0], x[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing an ALS-based Movie Recommendation Model Using the Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rank = 13\n",
    "best_iteration = 30\n",
    "best_regularization_param = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ALS.train(ratings2_RDD, best_rank, seed=17, iterations=best_iteration, lambda_=best_regularization_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate an ALS model\n",
    "The standard procedure in evaluating a machine learning model involves two steps:\n",
    "- Step 1: Using the model to generate **predicted output** for validation data.\n",
    "- Step 2: Compare the **predicted output** of validation data with the **actual output** of validation data to calculate **validation errors**.\n",
    "\n",
    "## <ALS model>.predictAll method\n",
    "- takes an RDD in the format of (\\<user_ID\\>, \\<movie_ID\\>)\n",
    "- returns an RDD in the format of (\\<user_ID\\>, \\<movie_ID\\>, \\<predicted rating\\>)\n",
    "\n",
    "## Using RDD-based join for model evaluation\n",
    "- Because this program uses RDD-based ALS model learning in MLlib PySpark module, we will use RDD-based join to combine actual output and predicted output for each input user-movie pair. \n",
    "- Because we want to combine predicted output and actual output for each input user-movie pair, we can use user-movie pairs as **keys** in RDD-based join.\n",
    "- Therefore, we want to transform RDDs that contain target/actual output into a key-value pair format where the key is user-movie pair.\n",
    "- Similarly, we want to transform RDDs that contain predicted output into a key-value pair format where the key is user-movie pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding all Genres\n",
    "We want to find all genres in the movies so that we can evaluate and compare the average prediction across all genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MovieID: integer (nullable = true)\n",
      " |-- MovieTitle: string (nullable = true)\n",
      " |-- Genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies2_DF = movies_DF.withColumn(\"GenresList\", split(col(\"Genres\"), '\\|'))\n",
    "# Notice: We used \"GenresList\" as the name of the column, which is a bit different from a similar column in previous labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MovieID: integer (nullable = true)\n",
      " |-- MovieTitle: string (nullable = true)\n",
      " |-- Genres: string (nullable = true)\n",
      " |-- GenresList: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies2_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "|MovieID|          MovieTitle|              Genres|          GenresList|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|[Adventure, Anima...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|[Adventure, Child...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|   [Comedy, Romance]|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies2_DF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_rdd = movies2_DF.select(\"GenresList\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(GenresList=['Adventure', 'Animation', 'Children', 'Comedy', 'Fantasy']),\n",
       " Row(GenresList=['Adventure', 'Children', 'Fantasy']),\n",
       " Row(GenresList=['Comedy', 'Romance'])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_rdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We want to obtain and flatten the content of \"GenresList\" from each Row object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_flatten_rdd = genres_rdd.flatMap(lambda x: x[\"GenresList\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adventure', 'Animation', 'Children']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_flatten_rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_count_rdd = genres_flatten_rdd.map(lambda x: (x, 1)).reduceByKey(lambda a, b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Adventure', 1117), ('Animation', 447), ('Children', 583)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_count_rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres_list = genres_count_rdd.map(lambda x: x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adventure', 'Animation', 'Children', 'Comedy', 'Fantasy', 'Romance', 'Drama', 'Action', 'Crime', 'Thriller', 'Horror', 'Mystery', 'Sci-Fi', 'Documentary', 'IMAX', 'War', 'Musical', 'Western', 'Film-Noir', '(no genres listed)']\n"
     ]
    }
   ],
   "source": [
    "print(all_genres_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Rating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_prediction_RDD = model.predictAll(ratings_input_RDD).map(lambda x: ( (x[0], x[1] ), x[2] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((253, 37739), 3.316578140685179),\n",
       " ((547, 142192), 3.3128919479037706),\n",
       " ((599, 69069), 3.9300891532733977)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_prediction_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_evaluation_RDD = ratings2_RDD.map(lambda x: ((x[0], x[1]), x[2])).join(ratings_prediction_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 31), (2.5, 2.1610668335889045)),\n",
       " ((1, 1029), (3.0, 2.5177951218502104)),\n",
       " ((1, 1061), (3.0, 2.4485821501198686))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_evaluation_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_prediction_error_RDD= ratings_evaluation_RDD.map(lambda x: (x[0], abs(x[1][0]-x[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 31), 0.3389331664110955),\n",
       " ((1, 1029), 0.48220487814978963),\n",
       " ((1, 1061), 0.5514178498801314)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_prediction_error_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserMovieError_RDD = ratings_prediction_error_RDD.map(lambda x: (x[0][0], x[0][1], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnNames=[\"UserID\", \"MovieID\", \"error\"]\n",
    "UserMovieError_DF = UserMovieError_RDD.toDF(ColumnNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------------------+\n",
      "|UserID|MovieID|              error|\n",
      "+------+-------+-------------------+\n",
      "|     1|     31| 0.3389331664110955|\n",
      "|     1|   1029|0.48220487814978963|\n",
      "|     1|   1061| 0.5514178498801314|\n",
      "|     1|   1129| 0.2525636057718841|\n",
      "|     1|   1263| 0.5406837054455749|\n",
      "+------+-------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "UserMovieError_DF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Prediction Error for Each Movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the sum of prediction error for each movie (across all users who provided rating for the movie) by applying ``sum(<column name>)`` to the result of ``groupBy(\"MovieID\")``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorSum_DF = UserMovieError_DF.groupBy(\"MovieID\").sum(ColumnNames[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|MovieID|        sum(error)|\n",
      "+-------+------------------+\n",
      "|    474|49.060900116248774|\n",
      "|   4823|  8.72990998273784|\n",
      "|  72011|13.512975934033253|\n",
      "+-------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ErrorSum_DF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|MovieID|count|\n",
      "+-------+-----+\n",
      "|    474|   80|\n",
      "|   4823|   19|\n",
      "|  72011|   26|\n",
      "+-------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RatingCount_DF = UserMovieError_DF.groupBy(\"MovieID\").count()\n",
    "RatingCount_DF.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame-based Join\n",
    "- When two PySpark DataFrames are joined on a common column, all of their columns are in the joined DataFrame.\n",
    "\n",
    "The code below perform an inner join between (1) the DF that contains the sum of prediction errors for each movie and (2) the DF that contains the total review count for each movie.  The joined DF formed can then be used to calculate the average prediction error for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Joined_Error_DF = ErrorSum_DF.join(RatingCount_DF, \"MovieID\", \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+\n",
      "|MovieID|        sum(error)|count|\n",
      "+-------+------------------+-----+\n",
      "|    474|49.060900116248774|   80|\n",
      "|   4823|  8.72990998273784|   19|\n",
      "|  72011|13.512975934033253|   26|\n",
      "+-------+------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Joined_Error_DF.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the average preduction error for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+------------------+\n",
      "|MovieID|        sum(error)|count|          AvgError|\n",
      "+-------+------------------+-----+------------------+\n",
      "|    474|49.060900116248774|   80|1.6306264216604602|\n",
      "|   4823|  8.72990998273784|   19| 2.176425649012396|\n",
      "|  72011|13.512975934033253|   26|1.9240765414609684|\n",
      "+-------+------------------+-----+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Avg_Error_DF=Joined_Error_DF.withColumn(\"AvgError\", col(\"count\")/col(\"sum(error)\") )\n",
    "Avg_Error_DF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sorted_Avg_Error_DF = Avg_Error_DF.orderBy(\"AvgError\", ascending=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----+------------------+\n",
      "|MovieID|          sum(error)|count|          AvgError|\n",
      "+-------+--------------------+-----+------------------+\n",
      "|  39408| 0.02084106280359921|    1|47.982197905343966|\n",
      "|  66659| 0.02285522764006953|    1| 43.75366615236906|\n",
      "|  48522|0.023163833147860247|    1| 43.17074784716168|\n",
      "|   8963|0.025675803713772927|    1| 38.94717420135064|\n",
      "|   7282|0.026275807300993437|    1| 38.05782210779845|\n",
      "|   8859|0.052726878410906175|    2|37.931318148853556|\n",
      "|  54290|0.052726878410906175|    2|37.931318148853556|\n",
      "|   7093|0.026409368693345425|    1| 37.86535042210145|\n",
      "|  26157|0.026729728498679606|    1| 37.41152851774749|\n",
      "|  26485|0.026729728498679606|    1| 37.41152851774749|\n",
      "+-------+--------------------+-----+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Sorted_Avg_Error_DF.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "``<DF>.corr(<column 1>, <column 2>)`` computes the correlation between the two columns provided. \n",
    "\n",
    "## Computing the correlation between the count of movie reviews and the average prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2426947005145335"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sorted_Avg_Error_DF.corr((\"count\"),(\"AvgError\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/storage/home/RecommendationErrorByMovie\"\n",
    "Sorted_Avg_Error_DF.write.option(\"header\", True).csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ALS-based recommendation system with any weakness in predicting ratings for a genre?  If so, which genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adventure', 'Animation', 'Children', 'Comedy', 'Fantasy', 'Romance', 'Drama', 'Action', 'Crime', 'Thriller', 'Horror', 'Mystery', 'Sci-Fi', 'Documentary', 'IMAX', 'War', 'Musical', 'Western', 'Film-Noir', '(no genres listed)']\n"
     ]
    }
   ],
   "source": [
    "print(all_genres_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completing the code below to perform inner join of the movies2_DF with Sorted_Avg_Error_DF on the common column \"MovieID\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MovieID: integer (nullable = true)\n",
      " |-- MovieTitle: string (nullable = true)\n",
      " |-- Genres: string (nullable = true)\n",
      " |-- GenresList: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies2_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "|MovieID|          MovieTitle|              Genres|          GenresList|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|[Adventure, Anima...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|[Adventure, Child...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|   [Comedy, Romance]|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|[Comedy, Drama, R...|\n",
      "|      5|Father of the Bri...|              Comedy|            [Comedy]|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies2_DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----+------------------+--------------------+--------------------+--------------------+\n",
      "|MovieID|         sum(error)|count|          AvgError|          MovieTitle|              Genres|          GenresList|\n",
      "+-------+-------------------+-----+------------------+--------------------+--------------------+--------------------+\n",
      "|    474| 49.060900116248774|   80|1.6306264216604602|In the Line of Fi...|     Action|Thriller|  [Action, Thriller]|\n",
      "|   4823|   8.72990998273784|   19| 2.176425649012396|  Serendipity (2001)|      Comedy|Romance|   [Comedy, Romance]|\n",
      "|  72011| 13.512975934033253|   26|1.9240765414609684|Up in the Air (2009)|       Drama|Romance|    [Drama, Romance]|\n",
      "| 142507|0.19692253527977277|    1| 5.078138967585782|Pawn Sacrifice (2...|               Drama|             [Drama]|\n",
      "|     29|  23.81569092993977|   40|1.6795649606669278|City of Lost Chil...|Adventure|Drama|F...|[Adventure, Drama...|\n",
      "+-------+-------------------+-----+------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_movies_error_DF = Sorted_Avg_Error_DF.join(movies2_DF, \"MovieID\", \"inner\")\n",
    "joined_movies_error_DF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing recommendation error for the genre first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_genre = \"Animation\"\n",
    "your_genre_recommendation_error_DF = joined_movies_error_DF.filter(array_contains(col(\"GenresList\"), your_genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+------------------+--------------------+--------------------+--------------------+\n",
      "|MovieID|        sum(error)|count|          AvgError|          MovieTitle|              Genres|          GenresList|\n",
      "+-------+------------------+-----+------------------+--------------------+--------------------+--------------------+\n",
      "|    558| 7.552634919595203|    9|1.1916371035821722|Pagemaster, The (...|Action|Adventure|...|[Action, Adventur...|\n",
      "| 152081| 4.154965898356528|    9|2.1660827598031305|     Zootopia (2016)|Action|Adventure|...|[Action, Adventur...|\n",
      "|    720|28.037990749396137|   45|1.6049652203044964|Wallace & Gromit:...|Adventure|Animati...|[Adventure, Anima...|\n",
      "|   3034|16.564021543223905|   29| 1.750782557504187|   Robin Hood (1973)|Adventure|Animati...|[Adventure, Anima...|\n",
      "+-------+------------------+-----+------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "your_genre_recommendation_error_DF.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MovieID: long (nullable = true)\n",
      " |-- sum(error): double (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      " |-- AvgError: double (nullable = true)\n",
      " |-- MovieTitle: string (nullable = true)\n",
      " |-- Genres: string (nullable = true)\n",
      " |-- GenresList: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "your_genre_recommendation_error_DF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation By a Column\n",
    "``<DF>.agg({<column name>: <agg operator>})`` applies an aggregation operator to a column of the DataFrame.  Examples of aggregation operator include\n",
    "- 'sum': adding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_genre_recommendation_AvgError_sum = your_genre_recommendation_error_DF.agg({'AvgError': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|     sum(AvgError)|\n",
      "+------------------+\n",
      "|1809.4138300155257|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "your_genre_recommendation_AvgError_sum.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect()\n",
    "Collect() can be applied to small DataFrame and small RDD to retrieve all of its contents (return as a list of ``Row`` objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_genre_recommendation_AvgError_sum_list = your_genre_recommendation_AvgError_sum.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(sum(AvgError)=1809.4138300155257)]\n"
     ]
    }
   ],
   "source": [
    "print(your_genre_recommendation_AvgError_sum_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_genre_recommendation_AvgError_sum_value = your_genre_recommendation_AvgError_sum_list[0]['sum(AvgError)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1809.4138300155257\n"
     ]
    }
   ],
   "source": [
    "print(your_genre_recommendation_AvgError_sum_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447\n"
     ]
    }
   ],
   "source": [
    "your_genre_movies_count = your_genre_recommendation_error_DF.count()\n",
    "print(your_genre_movies_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.047905659989991\n"
     ]
    }
   ],
   "source": [
    "recommendation_Err_your_genre = your_genre_recommendation_AvgError_sum_value/your_genre_movies_count\n",
    "print(recommendation_Err_your_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completing the code below to compute average prediction error for each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "generes_error_df = pd.DataFrame( columns = ['Genre', 'Movie Count', 'Average Review Count', 'Average Recommendation Error'] )\n",
    "index = 0\n",
    "for g in all_genres_list:\n",
    "    g_movies_error_DF = joined_movies_error_DF.filter(array_contains(\"GenresList\", g))\n",
    "    # We add persist to g_movies_error_DF because this DF is going to be used twice below.\n",
    "    g_movies_error_DF.persist()\n",
    "    g_movies_AvgError_sum = g_movies_error_DF.agg({'AvgError': 'sum' }).collect()[0]['sum(AvgError)']\n",
    "    g_movies_count = g_movies_error_DF.count()\n",
    "    g_movies_AvgError = g_movies_AvgError_sum / g_movies_count\n",
    "    # Also compute average number of reviews for movies in the genre\n",
    "    g_movies_ReviewCount = g_movies_error_DF.agg({'count': 'sum' }).collect()[0]['sum(count)']\n",
    "    g_movies_AvgReview = g_movies_ReviewCount / g_movies_count\n",
    "    generes_error_df.loc[index] = [ g, g_movies_count, g_movies_ReviewCount, g_movies_AvgError]\n",
    "    g_movies_error_DF.unpersist()\n",
    "    index = index +1                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The output path so that your Pandas dataframe for storing the average prediction error for each genre can be saved in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/storage/home/RecommendationWeaknessByGenre.csv\"\n",
    "generes_error_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
